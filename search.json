[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Facebook Messenger Data Part 1: Latent Dirichlet Allocation\n\n\n\nLDA\n\nPython\n\n\n\nIdentification and classification of topics in Facebook Messenger conversations using Latent Dirichlet Allocation (LDA).\n\n\n\nHarry Zhong\n\n\nJan 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Classification using PyTorch\n\n\n\nGender Classification\n\nNeural Networks\n\nPython\n\nPyTorch\n\n\n\nClassification of faces into genders using a convolutional neural network with residual layers.\n\n\n\nHarry Zhong\n\n\nMay 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of My Spotify Data\n\n\n\nK-means\n\nR\n\n\n\nCategorisation of my Spotify listening history using k-means clustering.\n\n\n\nHarry Zhong\n\n\nMar 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nHonours Thesis: Stochastic Volatility\n\n\n\nR\n\n\n\nResearch involving stochastic modelling to compare constant and stochastic volatility under geometric Brownian motion.\n\n\n\nHarry Zhong\n\n\nMay 19, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/spotify-analysis/index.html",
    "href": "projects/spotify-analysis/index.html",
    "title": "Analysis of My Spotify Data",
    "section": "",
    "text": "The motivation for this project was:\n\nI thought it would be fun.\nThat’s it.\n\nSo, let’s get into how we can use R and Spotify’s Web API to categorise songs that we have listened to."
  },
  {
    "objectID": "projects/spotify-analysis/index.html#activity-history-data",
    "href": "projects/spotify-analysis/index.html#activity-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Activity History Data",
    "text": "Activity History Data\nOur Spotify activity history data is given as a set of .json files. We can extract the data from all the .json files into a dataframe and perform some preliminary cleaning using the code below.\n\n\nActivity History Code\nfiles &lt;- list.files(\n  \"data/full_history_data\", \n  pattern = \"*.json\", \n  full.names = TRUE\n)\n\nfull_streaming_history &lt;- foreach(\n  file = files, \n  .packages = c(\"jsonlite\"),\n  .combine = rbind\n) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(\n    track_name = \"master_metadata_track_name\",\n    artist_name = \"master_metadata_album_artist_name\"\n  ) %&gt;%\n  mutate(\n    track_uri = gsub(\n      \"spotify:track:\", \n      \"\", \n      spotify_track_uri\n    ),\n    month = ts %&gt;%\n      substring(1, 7) %&gt;%\n      paste0(\"-01\") %&gt;%\n      ymd()\n  ) %&gt;%\n  select(\n    -spotify_track_uri,\n    -username,\n    -platform,\n    -ip_addr_decrypted\n  ) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nts\nms_played\nconn_country\nuser_agent_decrypted\ntrack_name\nartist_name\nmaster_metadata_album_album_name\nepisode_name\nepisode_show_name\nspotify_episode_uri\nreason_start\nreason_end\nshuffle\nskipped\noffline\noffline_timestamp\nincognito_mode\ntrack_uri\nmonth\n\n\n\n\n2024-02-08T23:57:04Z\n2072\nAU\nunknown\nKiss Me More (feat. SZA)\nDoja Cat\nPlanet Her\nNA\nNA\nNA\ntrackdone\nfwdbtn\nFALSE\nTRUE\nFALSE\n1707436622\nFALSE\n3DarAbFujv6eYNliUTyqtz\n2024-02-01\n\n\n2024-02-08T23:57:01Z\n219724\nAU\nunknown\nvampire\nOlivia Rodrigo\nGUTS\nNA\nNA\nNA\nfwdbtn\ntrackdone\nFALSE\nFALSE\nFALSE\n1707436403\nFALSE\n1kuGVB7EU95pJObxwvfwKS\n2024-02-01\n\n\n2024-02-08T23:53:23Z\n2284\nAU\nunknown\nJudas\nLady Gaga\nBorn This Way\nNA\nNA\nNA\nfwdbtn\nfwdbtn\nFALSE\nTRUE\nFALSE\n1707436400\nFALSE\n7F25roCtYi55JouckaayPC\n2024-02-01\n\n\n2024-02-08T23:53:20Z\n1721\nAU\nunknown\nHeads Will Roll\nYeah Yeah Yeahs\nIt’s Blitz!\nNA\nNA\nNA\nfwdbtn\nfwdbtn\nFALSE\nTRUE\nFALSE\n1707436398\nFALSE\n2WRFD9WczJ975X2K1Y9YVs\n2024-02-01\n\n\n2024-02-08T23:53:18Z\n4018\nAU\nunknown\nWhat You Waiting For?\nGwen Stefani\nLove Angel Music Baby\nNA\nNA\nNA\nfwdbtn\nfwdbtn\nFALSE\nTRUE\nFALSE\n1707436394\nFALSE\n0ny5zITdmyNwyTPVzRGscU\n2024-02-01\n\n\n2024-02-08T23:53:14Z\n2404\nAU\nunknown\nSpace Song\nBeach House\nDepression Cherry\nNA\nNA\nNA\nfwdbtn\nfwdbtn\nFALSE\nTRUE\nFALSE\n1707436392\nFALSE\n3CLhX1JkJZ4s5umNnOqCRh\n2024-02-01\n\n\n\n\n\nFrom here, we can use the ggplot2 and shiny packages to visualise trends in my most listened to artists and tracks.\n\n\n\napp.R\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(foreach)\n\nfiles &lt;- list.files(\n  paste0(here(), \"/data/full_history_data\"), \n  pattern = \"*.json\", \n  full.names = TRUE\n)\n\nfull_streaming_history &lt;- foreach(\n  file = files, \n  .packages = c(\"jsonlite\"),\n  .combine = rbind\n) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(\n    track_name = \"master_metadata_track_name\",\n    artist_name = \"master_metadata_album_artist_name\"\n  ) %&gt;%\n  mutate(\n    track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n    month = ts %&gt;%\n      substring(1, 7) %&gt;%\n      paste0(\"-01\") %&gt;%\n      ymd()\n  ) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))\n\nmin_date &lt;- full_streaming_history %&gt;%\n  pull(month) %&gt;%\n  min()\n\nmax_date &lt;- full_streaming_history %&gt;%\n  pull(month) %&gt;%\n  max()\n\nui &lt;- fluidPage(\n  titlePanel(\"Spotify Streaming History\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\n        \"top_n\",\n        \"Top n\",\n        min = 1,\n        max = 20,\n        value = 10\n      ),\n      sliderInput(\n        \"dates\",\n        \"Streaming History Date Range\",\n        min = min_date,\n        max = max_date,\n        value = c(max_date %m-% months(6), max_date)\n      )\n    ),\n    mainPanel(\n      tabsetPanel(\n        type = \"tabs\",\n        tabPanel(\n          \"Artist History Plot\", \n          h2(textOutput(\"artist_history_title\")),\n          plotOutput(\"artist_history_plot\")\n        ),\n        tabPanel(\n          \"Track History Plot\",\n          h2(textOutput(\"track_history_title\")),\n          plotOutput(\"track_history_plot\")\n        )\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  output$artist_history_title &lt;- renderText({\n    top_n &lt;- input$top_n\n    \n    paste0(\n      \"Proportion of Hours Listened: Top \",\n      top_n,\n      \" Artists\"\n    )\n  })\n  \n  output$artist_history_plot &lt;- renderPlot({\n    top_artists &lt;- data.frame(\n      month = full_streaming_history %&gt;%\n        select(month) %&gt;%\n        distinct()\n    ) %&gt;%\n      mutate(\n        top_artists = map(\n          month,\n          ~full_streaming_history %&gt;%\n            filter(month == .x) %&gt;%\n            group_by(artist_name) %&gt;%\n            summarise(time = sum(ms_played)) %&gt;%\n            slice_max(time, n = as.numeric(input$top_n)) %&gt;%\n            pull(artist_name)\n        )\n      )\n    \n    artist_summary &lt;- full_streaming_history %&gt;%\n      filter(\n        month %&gt;%\n          between(input$dates[1], input$dates[2])\n      ) %&gt;%\n      left_join(\n        top_artists,\n        by = \"month\"\n      ) %&gt;%\n      rowwise() %&gt;%\n      filter(artist_name %in% top_artists) %&gt;%\n      group_by(\n        artist_name, \n        month\n      ) %&gt;%\n      summarise(hours_listened = sum(ms_played/(1000*60)))\n    \n    ggplot(artist_summary, aes(x = month, y = hours_listened, fill = artist_name, label = artist_name)) +\n      xlab(\"Date\") +\n      ylab(\"Proportion\") +\n      geom_bar(position = \"fill\", stat = \"identity\") +\n      geom_text(size = 3, position = position_fill(vjust = 0.5)) +\n      theme(legend.position = \"none\")\n  })\n  \n  output$track_history_title &lt;- renderText({\n    top_n &lt;- input$top_n\n    \n    paste0(\n      \"Proportion of Hours Listened: Top \",\n      top_n,\n      \" Tracks\"\n    )\n  })\n  \n  output$track_history_plot &lt;- renderPlot({\n    top_tracks &lt;- data.frame(\n      month = full_streaming_history %&gt;%\n        select(month) %&gt;%\n        distinct()\n    ) %&gt;%\n      mutate(\n        top_tracks = map(\n          month,\n          ~full_streaming_history %&gt;%\n            filter(month == .x) %&gt;%\n            mutate(track_artist_name = paste(track_name, artist_name, sep = \"\\n\")) %&gt;%\n            group_by(track_artist_name) %&gt;%\n            summarise(time = sum(ms_played)) %&gt;%\n            slice_max(time, n = as.numeric(input$top_n)) %&gt;%\n            pull(track_artist_name)\n        )\n      )\n    \n    track_summary &lt;- full_streaming_history %&gt;%\n      filter(\n        month %&gt;%\n          between(input$dates[1], input$dates[2])\n      ) %&gt;%\n      mutate(track_artist_name = paste(track_name, artist_name, sep = \"\\n\")) %&gt;%\n      left_join(\n        top_tracks,\n        by = \"month\"\n      ) %&gt;%\n      rowwise() %&gt;%\n      filter(track_artist_name %in% top_tracks) %&gt;%\n      group_by(\n        track_artist_name, \n        month\n      ) %&gt;%\n      summarise(hours_listened = sum(ms_played/(1000*60)))\n    \n    ggplot(track_summary, aes(x = month, y = hours_listened, fill = track_artist_name, label = track_artist_name)) +\n      xlab(\"Date\") +\n      ylab(\"Proportion\") +\n      geom_bar(position = \"fill\", stat = \"identity\") +\n      geom_text(size = 3, position = position_fill(vjust = 0.5)) +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#track-feature-data",
    "href": "projects/spotify-analysis/index.html#track-feature-data",
    "title": "Analysis of My Spotify Data",
    "section": "Track Feature Data",
    "text": "Track Feature Data\nNext, we’ll need to use Spotify’s Web API to obtain track features, which requires the track ID of each track we’re interested in. Fortunately, since we requested our full activity history, this data is included as a column.\n\n\n\n\n\n\nNote\n\n\n\nOn the topic of Spotify’s Web API, it’s interesting to note that it also includes genres. However, genres are linked to artists, not tracks, which makes this feature less noteworthy compared to track features.\n\n\nWe can use the httr and jsonlite packages to create a function that takes a Spotify track ID and returns its track features.\n\nget_audio_features &lt;- function(track_id) {\n  url = paste0(\"https://api.spotify.com/v1/audio-features/\", track_id)\n  response &lt;- GET(\n    url,\n    add_headers(Authorization = paste(\"Bearer\", spotify_token))\n  )\n  data &lt;- fromJSON(\n    content(\n      response, \n      \"text\", \n      encoding = \"UTF-8\"\n    )\n  )\n  return(data)\n}\n\nGiven the large number of track IDs, using this function on all tracks in our dataset is a long and painful process, where we will get rate limited many times by Spotify. Conveniently, I have a local file containing all of our tracks and their associated track features, which I will load in.\nThe description for each feature can be found in Spotify’s documentation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrack_name\nartist_name\ntrack_uri\ndanceability\nenergy\nkey\nloudness\nmode\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nduration_ms\ntime_signature\n\n\n\n\nPsychedelic Switch\nCarly Rae Jepsen\n7zy2kNoeD72x2NEDaAsJOX\n0.681\n0.805\n4\n-6.676\n1\n0.0480\n0.00182\n1.58e-02\n0.341\n0.304\n127.907\n272035\n4\n\n\nSick Feeling\nboy pablo\n7zxLkZbUxITHabPzGN8Xgc\n0.415\n0.504\n9\n-10.003\n1\n0.0318\n0.02200\n3.80e-06\n0.363\n0.401\n165.860\n155714\n4\n\n\nYou Get Me So High\nThe Neighbourhood\n7zwn1eykZtZ5LODrf7c0tS\n0.551\n0.881\n7\n-6.099\n0\n0.0542\n0.18600\n7.91e-02\n0.152\n0.387\n88.036\n153000\n4\n\n\nNo Different\nEpik High\n7ztlf9mCrjoLXAYYf0LCYx\n0.732\n0.600\n1\n-6.127\n1\n0.0535\n0.03070\n8.25e-05\n0.137\n0.238\n131.912\n200362\n4\n\n\nSorry\nThe Rose\n7zmrZMinkTMJ2kZgM9Kqgp\n0.388\n0.642\n10\n-4.659\n1\n0.0337\n0.47100\n0.00e+00\n0.306\n0.402\n173.610\n215477\n4\n\n\nLivin It Up (with Post Malone & A$AP Rocky)\nYoung Thug\n7zjEyeBsaw9gV0jofJLfOM\n0.767\n0.313\n7\n-12.059\n1\n0.0798\n0.83800\n0.00e+00\n0.105\n0.765\n82.582\n210907\n4\n\n\n\n\n\nWe can then remove discrete track features and scale the remaining features so that the clusters are not affected by the difference in magnitude of different features.\n\nfeature_matrix &lt;- full_track_features %&gt;%\n  mutate(track_artist = paste(track_name, artist_name, sep = \" - \")) %&gt;%\n  select(\n    -track_name, \n    -artist_name\n  ) %&gt;%\n  column_to_rownames(var = \"track_artist\") %&gt;%\n  select(\n    -track_uri,\n    -key,\n    -mode,\n    -time_signature\n  ) %&gt;%\n  scale()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndanceability\nenergy\nloudness\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nduration_ms\n\n\n\n\nPsychedelic Switch - Carly Rae Jepsen\n0.5034878\n1.3400006\n0.4206709\n-0.3325940\n-1.3132909\n-0.3305910\n1.3463448\n-0.5950222\n0.3365591\n1.3459625\n\n\nSick Feeling - boy pablo\n-1.2632525\n-0.0712252\n-0.3296591\n-0.5474916\n-1.2506975\n-0.3915509\n1.5205894\n-0.1757695\n1.6071509\n-0.7309358\n\n\nYou Get Me So High - The Neighbourhood\n-0.3599567\n1.6963234\n0.5508003\n-0.2503492\n-0.7420099\n-0.0863063\n-0.1505748\n-0.2362802\n-0.9982436\n-0.7793940\n\n\nNo Different - Epik High\n0.8422237\n0.3788667\n0.5444855\n-0.2596349\n-1.2237122\n-0.3912473\n-0.2693779\n-0.8802870\n0.4706386\n0.0662492\n\n\nSorry - The Rose\n-1.4425833\n0.5757820\n0.8755599\n-0.5222876\n0.1419900\n-0.3915657\n1.0691375\n-0.1714473\n1.8666057\n0.3361258\n\n\nLivin It Up (with Post Malone & A$AP Rocky) - Young Thug\n1.0746895\n-0.9667206\n-0.7933436\n0.0892422\n1.2803337\n-0.3915657\n-0.5228246\n1.3975087\n-1.1808328\n0.2545290"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#what-is-k-means",
    "href": "projects/spotify-analysis/index.html#what-is-k-means",
    "title": "Analysis of My Spotify Data",
    "section": "What is K-means?",
    "text": "What is K-means?\nThe k-means algorithm basically goes:\n\nChoose \\(k\\) random points within the domain of your factors.\nCreate \\(k\\) clusters by assigning each observation to its nearest point, which is now referred to as a mean.\nThe centroid of each cluster then becomes the new mean.\nRepeat until convergence.\n\nThe obvious question is: how do we determine the value of \\(k\\) for a given set of factors? One method would be to use something called a silhouette value. We can understand the silhouette value by considering a group of clustered data points, shown below.\n\n\nChart Code\nset.seed(2687)\n\nrand_data &lt;- data.frame(\n  x = rnorm(50),\n  y = rnorm(50)\n)\n\nkm &lt;- kmeans(rand_data, 3)\n\nfviz_cluster(\n  km,\n  data = rand_data,\n  geom = \"point\"\n)\n\n\n\n\n\n\n\n\n\nWe’ll let \\(s_i\\) be the silhouette value for point \\(i\\) which belongs to cluster \\(C_I\\), then\n\\[\n\\begin{split}\ns_i&=\\frac{b_i-a_i}{\\text{max}(a_i,b_i)},\\text{ if }|C_I|&gt;1,\\\\\ns_i&=0,\\text{ if }|C_I|=0,\n\\end{split}\n\\]\nwhere\n\\[\n\\begin{split}\na_i&=\\frac{1}{|C_I|-1}\\sum_{j\\in C_I,i\\neq j}\\text{d}(i,j),\\\\\nb_i&=\\text{min}\\frac{1}{|C_J|}\\sum_{j\\in C_J}\\text{d}(i,j),\\text{ where }J\\neq I.\n\\end{split}\n\\]\nSimply put, \\(a_i\\) is the average of some measure of distance between point \\(i\\) and every other point in cluster \\(C_I\\) besides itself, and \\(b_i\\) is the minimum average of some measure of distance between \\(i\\) and every other point in some other cluster \\(C_J\\). The cluster \\(C_J\\), used to determine \\(b_i\\), is sometimes referred to as the neighboring cluster of point \\(i\\) as it is the next closest cluster after \\(C_I\\).\nThus, given the definition of \\(s_i\\), higher values of \\(s_i\\) indicate a better fit of a point \\(i\\) in its cluster \\(C_I\\).\nFollowing the definition of a silhouette value for a single point, the clustering performance of the entire dataset is calculated via the average silhouette value of all points.\nThus, we can determine the optimal number of clusters by:\n\nRunning the k-means algorithm using \\(n\\) clusters.\nEvaluating the average silhouette value.\nRepeat for a reasonable range of \\(n\\).\nRanking \\(n\\) by maximum average silhouette value.\n\nConveniently, the fviz_nbclust function takes care of this process for us."
  },
  {
    "objectID": "projects/spotify-analysis/index.html#feature-selection",
    "href": "projects/spotify-analysis/index.html#feature-selection",
    "title": "Analysis of My Spotify Data",
    "section": "Feature selection",
    "text": "Feature selection\nThe next problem is finding the optimal features to include our model. Generally speaking, an easy way to determine the relevant features to include in a model is to use domain knowledge. However, we do not have this luxury as I know nothing about audio engineering. So, we will do it the hard way, by trying every combination of features and selecting the ones with the best performance.\nTo do this, we can use a function I wrote that does the following:\n\nTakes inputs n, data, nstart, itermax. Where n is is the number of factors to consider, and data is the feature matrix previously generated. The nstart and itermax inputs are values passed on to the kmeans function.\nFinds all combinations of n factors within data.\nFor each combination, determine the optimal number of clusters using using average silhouette value, and fit k-means clusters.\nRecords performance metrics and cluster plot.\n\nThe function then outputs a dataframe that contains a row for each combination of n factors.\n\n\nFunction Code\nkmeans_select_features &lt;- function(n, data, nstart, itermax) {\n  comb_n &lt;- data %&gt;%\n    colnames() %&gt;%\n    combn(n, simplify = FALSE)\n  \n  old_cols &lt;- seq(1, n)\n  new_cols &lt;- paste0(\"factor_\", seq(1, n))\n  \n  new_cols_sym &lt;- syms(new_cols)\n  \n  factor_combinations_n &lt;- do.call(rbind.data.frame, comb_n) %&gt;%\n    rename_with(~new_cols, all_of(old_cols)) %&gt;%\n    mutate(factors = pmap(list(!!!new_cols_sym), c)) %&gt;%\n    mutate(n_factors = n) %&gt;%\n    select(-(!!new_cols)) %&gt;%\n    mutate(data = map(factors,\n                      ~data %&gt;%\n                        as.data.frame() %&gt;%\n                        select(all_of(.x)))) %&gt;%\n    mutate(n_clusters = map(data,\n                            ~fviz_nbclust(.x, \n                                          kmeans, \n                                          nstart = nstart, \n                                          iter.max = itermax)[[\"data\"]] %&gt;%\n                              slice(which.max(y)) %&gt;%\n                              select(clusters) %&gt;%\n                              as.numeric(),\n                            .progress = paste(\"Finding optimal n_clusters:\", \n                                              n, \n                                              \"factors\")) %&gt;%\n             as.numeric()) %&gt;% \n    mutate(km = map2(data,\n                     n_clusters,\n                     ~kmeans(.x, \n                             .y, \n                             nstart = nstart, \n                             iter.max = itermax,\n                             algorithm = \"MacQueen\"),\n                     .progress = paste(\"Calculating kmeans:\", \n                                       n, \n                                       \"factors\"))) %&gt;%\n    mutate(total_withinss = map(km,\n                                ~.x$tot.withinss) %&gt;%\n             as.numeric(),\n           bsstssRatio = map(km,\n                             ~.x$betweenss/.x$totss) %&gt;%\n             as.numeric()) %&gt;%\n    mutate(km_plot = map2(km,\n                          data,\n                          ~fviz_cluster(.x,\n                                        data = .y,\n                                        geom = \"point\",\n                                        ellipse.type = \"convex\"))) %&gt;%\n    arrange(desc(bsstssRatio))  \n  \n  return(factor_combinations_n)\n}\n\n\nThe function can then be used on all values of n, from 2 to the total number of factors. As this process is computationally intensive, and most R packages do not support multi-threading, we can use the foreach and doParallel packages to write a multi-threaded for loop which utilises all cores of the local computer. If we paid for all our CPU cores, we might as well use them right?\n\nset.seed(2687)\n\ncl &lt;- makeCluster(detectCores())\nregisterDoParallel(cl)\n\nkmeans_nfact &lt;- foreach(n = seq(2, ncol(feature_matrix)),\n                        .packages = c(\n                          \"tidyverse\",\n                          \"cluster\",\n                          \"factoextra\",\n                          \"rlang\"\n                        ),\n                        .combine = bind_rows) %dopar% {\n                          kmeans_select_features(n, feature_matrix, 25, 1000)\n                        } %&gt;% \n  arrange(desc(bsstssRatio))\n\nstopCluster(cl)\n\nThis results in a dataframe containing all possible combinations of factors for our dataset, and their k-means clustering results and performance, based on a value of \\(k\\) determined by average silhouette value."
  },
  {
    "objectID": "projects/spotify-analysis/index.html#cluster-playlists",
    "href": "projects/spotify-analysis/index.html#cluster-playlists",
    "title": "Analysis of My Spotify Data",
    "section": "Cluster Playlists",
    "text": "Cluster Playlists\nJust for fun, and to see if our subjective interpretation of grouping songs together aligns at all with k-means and Spotify’s API, we can calculate the top 5 tracks by hours listened for each cluster in the highest performing k-means result.\n\n\nTop 5 Tracks Code\ncluster_top_tracks &lt;- kmeans_nfact_save %&gt;%\n  slice(1) %&gt;%\n  pull(km) %&gt;%\n  pluck(1) %&gt;%\n  pluck(\"cluster\") %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"track_artist\") %&gt;%\n  rename(cluster = 2) %&gt;% \n  mutate(cluster = paste0(\"Cluster \", cluster)) %&gt;%\n  left_join(\n    full_streaming_history %&gt;%\n      select(\n        track_name,\n        artist_name,\n        ms_played\n      ) %&gt;%\n      na.omit() %&gt;%\n      group_by(\n        track_name,\n        artist_name\n      ) %&gt;%\n      summarise(\n        hours_listened = sum(ms_played/(1000*60))\n      ) %&gt;%\n      mutate(\n        track_artist = paste(\n          track_name,\n          artist_name,\n          sep = \" - \"\n        )\n      ),\n      .,\n      by = \"track_artist\"\n    ) %&gt;%\n  select(-track_artist) %&gt;%\n  group_by(cluster) %&gt;%\n  slice_max(hours_listened, n = 5) %&gt;%\n  ungroup() %&gt;%\n  select(\n    cluster,\n    track_name,\n    artist_name\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ncluster\ntrack_name\nartist_name\n\n\n\n\nCluster 1\ni &lt;3 u\nboy pablo\n\n\nCluster 1\nApocalypse\nCigarettes After Sex\n\n\nCluster 1\nNothing\nBruno Major\n\n\nCluster 1\nSunsetz\nCigarettes After Sex\n\n\nCluster 1\nWonder\nADOY\n\n\nCluster 2\nMay I Ask\nLuke Chiang\n\n\nCluster 2\ndrunk\nkeshi\n\n\nCluster 2\nis your bedroom ceiling bored? (feat. Rxseboy) - Fudasca Remix\nSody\n\n\nCluster 2\ndrivers license\nOlivia Rodrigo\n\n\nCluster 2\nLocation Unknown ◐\nHONNE\n\n\nCluster 3\nchange ur mind\nSarcastic Sounds\n\n\nCluster 3\nstay4ever (feat. Mounika.)\nPowfu\n\n\nCluster 3\naffection\nBETWEEN FRIENDS\n\n\nCluster 3\nboyfriend (with Social House)\nAriana Grande\n\n\nCluster 3\nnot ur friend\nJeremy Zucker\n\n\n\n\n\nThen, we can make some playlists:\n\nCluster 1 Playlist\n\n\n\nCluster 2 Playlist\n\n\n\nCluster 3 Playlist"
  },
  {
    "objectID": "projects/gender-nn/index.html",
    "href": "projects/gender-nn/index.html",
    "title": "Gender Classification using PyTorch",
    "section": "",
    "text": "Neural networks are cool, they can take complex tasks that are usually pretty easy for humans to do and automate them, given you have sufficient training data and computing power. In this project, we will explore how to make our own neural network, and attempt to predict the gender of faces.\nTo get a basic understanding of how neural networks, I would recommend watching 3Blue1Brown’s YouTube playlist on neural networks. As neural networks are slightly more complicated than most common machine learning algorithms, I won’t go through the basics in much detail here."
  },
  {
    "objectID": "projects/gender-nn/index.html#training",
    "href": "projects/gender-nn/index.html#training",
    "title": "Gender Classification using PyTorch",
    "section": "Training",
    "text": "Training\nFor this project, we’ll require a dataset containing a large number of labelled images of faces, which as you can imagine isn’t all that common. Luckily for us, the CelebA is a publicly available labelled dataset of around 200k faces. As it’s a well known dataset, there is a function in torch that automatically downloads the required files (sometimes, usually the Google drive link is down) and creates a dataset object for the CelebA.\n\nimsize = int(128/0.8)\nbatch_size = 10\nclasses = ('Female', 'Male')\n\nfivecrop_transform = transforms.Compose([\n    transforms.Resize([imsize, imsize]),\n    transforms.Grayscale(1),\n    transforms.FiveCrop(int(imsize*0.8)),\n    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n])\n\ntrain_dataset = datasets.CelebA(\n    root = './',\n    split='all',\n    target_type='attr',\n    transform=fivecrop_transform,\n    download=True\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    generator=torch.Generator(device=device)\n)\n\nWe can verify the number of training images using len.\n\nlen(train_dataset)\n\n202599\n\n\nNote that the set of transformations applied to the training dataset contains FiveCrop in addition to the standard resize and grayscale transformations, FiveCrop makes 5 cropped versions of each image (who would have guessed), one for each corner plus centered. This improves model performance and reduces overfitting to the training dataset. However, this also increases the computational resources required to train the model on this dataset by a factor of 5.\n\n\n\n\n\n\nNote\n\n\n\nThere is also a TenCrop function which applies the transformations from FiveCrop, plus a vertical flip. I would have liked to use TenCrop, but my old MacBook did not agree with that decision.\n\n\nWe can then access a few sample training images and their labels as we did previously.\n\ntrain_data = iter(train_loader)\ntrain_images, train_labels = next(train_data)\n\n# Index of Male label, as CelebA contains multiple labels.\nfactor = functions.attributes.index('Male')\n\nfunctions.imshow(torchvision.utils.make_grid(\n    torch.cat((\n        train_images[0],\n        train_images[1],\n        train_images[2]\n    )),\n    nrow=5\n))\n\nfor i in range(3):\n    print(classes[train_labels[:, factor][i]])\n\n\n\n\n\n\n\n\nMale\nMale\nFemale"
  },
  {
    "objectID": "projects/gender-nn/index.html#testing",
    "href": "projects/gender-nn/index.html#testing",
    "title": "Gender Classification using PyTorch",
    "section": "Testing",
    "text": "Testing\nNext, we need a dataset to test the performance of our model on unseen data. The simple option would be to split CelebA into train and test partitions. However, I found achieving high test accuracy under this setup to be fairly simple, and resulted in poor performance on other image datasets.\nThus, we’ll use a Kaggle dataset of AI generated faces as the test dataset, which I found required a significantly more complicated model to achieve high accuracy in, but produced models with better performance when given a random selection of my own images.\n\ntest_transform = transforms.Compose([\n    transforms.Resize([int(imsize*0.8), int(imsize*0.8)]),\n    transforms.Grayscale(1),\n    transforms.ToTensor()\n])\n\ntest_dataset = datasets.ImageFolder(\n    root='ThisPersonDoesNotExist_resize/',\n    transform=test_transform\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    generator=torch.Generator(device=device)\n)\n\nOnce again, we can get the number of images in the test dataset.\n\nlen(test_dataset)\n\n6873\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis dataset was originally the training dataset, given significantly reduced number of images compared to CelebA, it’s unsurprising the initial models did not perform well.\n\n\nWe can then show a few images from the test dataset, along with their labels.\n\ntest_data = iter(test_loader)\ntest_images, test_labels = next(test_data)\n\nfunctions.imshow(torchvision.utils.make_grid(test_images, nrow=5))\n\nfor i in range(batch_size):\n    print(classes[test_labels[i]])\n\n\n\n\n\n\n\n\nFemale\nFemale\nMale\nFemale\nFemale\nFemale\nFemale\nFemale\nFemale\nMale"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harry Zhong",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Email\n  \n\n  \n  \n\n\nI am an Actuary (AIAA) working as an Analyst at Commonwealth Bank where I implement capital and provisions models.\nWhen I’m not studying for Fellowship exams, I code using Python and R. Sometimes I’ll make something interesting and it ends up on here.\n\n\n\nCommonwealth Bank | Analyst (Risk Analytics Strategic Initiatives) | Aug 2024 - Present\nEBM Insurance & Risk | Data Analyst | Nov 2022 - Jul 2024\n\n\n\nActuaries Institute | Fellowship Program (Banking)| Jan 2025 - May 2025\nActuaries Institute | Actuary Program | Jul 2023 - Oct 2023\nCurtin University | Bachelor of Science (Actuarial Science) (Honours) | Feb 2019 - Jun 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentification and classification of topics in Facebook Messenger conversations using Latent Dirichlet Allocation (LDA).\n\n\n\n\n\nJan 5, 2025\n\n\nHarry Zhong\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of faces into genders using a convolutional neural network with residual layers.\n\n\n\n\n\nMay 24, 2024\n\n\nHarry Zhong\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#recent-projects",
    "href": "index.html#recent-projects",
    "title": "Harry Zhong",
    "section": "",
    "text": "Identification and classification of topics in Facebook Messenger conversations using Latent Dirichlet Allocation (LDA).\n\n\n\n\n\nJan 5, 2025\n\n\nHarry Zhong\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of faces into genders using a convolutional neural network with residual layers.\n\n\n\n\n\nMay 24, 2024\n\n\nHarry Zhong\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/fbm_part1_lda/index.html",
    "href": "projects/fbm_part1_lda/index.html",
    "title": "Facebook Messenger Data Part 1: Latent Dirichlet Allocation",
    "section": "",
    "text": "After analysing my Spotify data, I thought it would be interesting to investigate another dataset generated by my online activity: Facebook Messenger chat logs. However, since chat logs are composed of text data we’ll have to learn some basic natural language processing techniques to gain any meaningful insights from this dataset.\nThis is part 1 of 2 of my analysis on my Facebook Messenger conversations, where I’ll use latent Dirichlet allocation to (hopefully) identify topics within conversations."
  },
  {
    "objectID": "projects/fbm_part1_lda/index.html#dirichlet-distribution",
    "href": "projects/fbm_part1_lda/index.html#dirichlet-distribution",
    "title": "Facebook Messenger Data Part 1: Latent Dirichlet Allocation",
    "section": "Dirichlet Distribution",
    "text": "Dirichlet Distribution\nThe Dirichlet distribution is a continuous multivariate distribution, LDA typically uses the symmetric case of the Dirichlet distribution where the parameter is sparse, defined by the probability density function:\n\\[\nf(x_1,...,x_K;\\alpha)=\\frac{\\Gamma(\\alpha K)}{\\Gamma(\\alpha)^K}\\prod_{i=1}^{K}x_i^{\\alpha-1}\n\\]\nWhere \\(\\Gamma(z)\\) is the Gamma function, and the following constraints are satisfied:\n\n\\(\\alpha &lt;1\\) (sparse condition).\n\\(K\\ge 2\\)\n\\(\\sum_{i=1}^K x_i=1\\)\n\\(x_i\\in [0,1]\\)\n\nWe can think of a Dirichlet distribution as a distribution of multinomial distributions, where \\(x_1,...,x_K\\) is the sample space of the multinomial distributions. The sparse condition (\\(\\alpha &lt;1\\)) indicates that the probability density function is greater around the points \\(x_1,...,x_K\\). Constraints 2 to 4 basically allows the domain of the Dirichlet PDF to satisfy the sample space of a multinomial distribution.\nThis distribution can intuitively be understood as a topic distribution for documents, as documents will typically have very few primary topics, and a sparse Dirichlet distribution will assign a higher probability to multinomial distributions that are heavily weighted to a few outcomes (topics). This works similarly for word distributions for topics, as topics will typically be defined by a handful of words."
  },
  {
    "objectID": "projects/fbm_part1_lda/index.html#document-generating-process",
    "href": "projects/fbm_part1_lda/index.html#document-generating-process",
    "title": "Facebook Messenger Data Part 1: Latent Dirichlet Allocation",
    "section": "Document Generating Process",
    "text": "Document Generating Process\nNow that we understand the relevant type of Dirichlet distribution, we’ll assign some parameters which will define how documents are generated under LDA, let:\n\n\\(M\\) be the number of documents.\n\\(N_i\\) be the number of words in document \\(i\\in \\{1,...,M\\}\\).\n\\(K\\) be the total number of topics across the \\(M\\) documents.\n\\(\\alpha\\) be the symmetric parameter of the Dirichlet distribution for topics within documents.\n\\(\\beta\\) be the symmetric parameter of the Dirichlet distribution for words within topics.\n\\(\\theta_i\\) be the multinomial topic distribution for document \\(i\\in \\{1,...,M\\}\\).\n\\(\\phi_k\\) be the multinomial word distribution for topic \\(k\\in \\{1,...,K\\}\\)\n\nSo we have \\(M\\) documents which each have a length of \\(N_i\\). To generate documents, we’ll first sample \\(\\phi_k\\sim Dir(\\beta)\\) for all \\(k\\). This gives us the multinomial word distribution for each of the \\(K\\) topics. Then, for each document \\(i\\):\n\nSample \\(\\theta_i\\sim Dir(\\alpha)\\). This gives us the multinomial topic distribution for document \\(i\\).\nGenerate word \\(j\\in \\{1,...,N_i\\}\\) in document \\(i\\) by:\n\nSampling a topic from \\(\\theta_i\\).\nSampling a word from the corresponding \\(\\phi_k\\) where \\(k\\) is the topic chosen previously.\n\nRepeat for all \\(i\\)."
  },
  {
    "objectID": "projects/fbm_part1_lda/index.html#training",
    "href": "projects/fbm_part1_lda/index.html#training",
    "title": "Facebook Messenger Data Part 1: Latent Dirichlet Allocation",
    "section": "Training",
    "text": "Training\nThe goal of model training is to find the \\(K\\) word distributions and \\(M\\) topic distributions which maximises the likelihood of the model generating the training data given the hyperparameters \\(\\alpha\\), \\(\\beta\\) and \\(K\\). There are various methods to achieve this, we’ll be using gensim.models.ldamodel.LdaModel which implements online leaning.\n\nCoherence Score\nNext, to evaluate the performance of trained models we’ll use UMass coherence. The idea behind UMass coherence is that words that come from the same topic should appear together in documents more often than not, so we take each word pair from the top \\(N\\) (gensim sets this as 20 by default) words of each topic and compare the probability of appearing together vs the probability of appearing by itself. UMass coherence for a topic is defined by the formula below.\n\\[\nUMass=\\frac{2}{N(N-1)}\\sum_{i=1}^N\\sum_{j=1}^{i-1}\\text{log}(\\frac{\\text{P}(w_i,w_j)+\\epsilon}{\\text{P}(w_j)})\n\\]\nWhere:\n\n\\((w_i,w_j)\\) is a word pair.\n\\(\\text{P}()\\) is the probability of the word/pair occurring calculated using the frequency observed in the training documents.\n\\(\\epsilon=1\\) to avoid \\(\\text{log}(0)\\).\n\n\n\nImplementation\nWe can then create a class that uses gensim to train the model, show the discovered topics and calculate the coherence score as an evaluation metric. For simplicity, we’ll leave \\(\\alpha\\) and \\(\\beta\\) as the default value in LdaModel which is 1/num_topics, this leave us with only num_topics as a tunable hyperparameter.\n\nclass fbm_lda:\n    def __init__(self, documents):\n        self.documents = documents\n        self.texts = [doc.split() for doc in documents]\n        self.dictionary = gs.corpora.Dictionary(self.texts)\n        self.corpus = [self.dictionary.doc2bow(text) for text in self.texts]\n    \n    def train_lda(self, num_topics, passes=10, random_state=2687):\n        self.num_topics = num_topics\n\n        self.lda_model = gs.models.ldamodel.LdaModel(\n            corpus=self.corpus,\n            num_topics=num_topics,\n            id2word=self.dictionary,\n            passes=passes,\n            random_state=random_state\n        )\n\n        return self.lda_model\n\n    def print_topics(self, num_words=5):\n        for topic in self.lda_model.print_topics(num_topics=self.num_topics, num_words=num_words):\n            print(topic)\n\n    def get_coherence(self, coherence_type='u_mass'):\n        coherence = gs.models.CoherenceModel(\n            model=self.lda_model,\n            texts=self.texts,\n            dictionary=self.dictionary,\n            coherence=coherence_type\n        )\n\n        return coherence.get_coherence()\n\nThis allows us to train a LDA model using our documents given a number of topics and calculate its coherence score.\n\nmodel = fbm_lda(documents)\nmodel.train_lda(5)\nmodel.get_coherence()\n\n-2.206920240598983"
  },
  {
    "objectID": "projects/fbm_part1_lda/index.html#hyperparameter-tuning",
    "href": "projects/fbm_part1_lda/index.html#hyperparameter-tuning",
    "title": "Facebook Messenger Data Part 1: Latent Dirichlet Allocation",
    "section": "Hyperparameter Tuning",
    "text": "Hyperparameter Tuning\nNaturally, the next step would be to test a range of values for num_topics to evaluate which ones gives the best UMass coherence score. This is easily done by extending the LDA class we created previously.\n\n\n\n\n\n\nNote\n\n\n\nAs someone who mainly uses R at work, extending a class with additional functionality like this is pretty neat.\n\n\n\nimport numpy as np\n\nclass tune_lda(fbm_lda):\n    def tune(self, n_start, n_stop, step, sort: bool=False):\n        n_topics_values = np.arange(n_start, n_stop, step)\n\n        tuning_results = pd.DataFrame(\n            columns=[\n                'n_topics',\n                'umass_coherence'\n            ]\n        )\n\n        for index in range(len(n_topics_values)):\n            n_topics = n_topics_values[index]\n            self.train_lda(num_topics=n_topics)\n            umass_coherence = self.get_coherence()\n\n            tuning_results.loc[index] = (\n                [n_topics] + \n                [umass_coherence]\n            )\n\n        if sort:\n            tuning_results = tuning_results.sort_values('umass_coherence', ascending=False)\n\n        return tuning_results\n\nThe new class can then easily be used to test values 2 to 20 for num_topics.\n\ntuning = tune_lda(documents)\ntuning_results = tuning.tune(2, 21, 1)\ntuning_results.plot(x='n_topics')"
  },
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "Web Apps",
    "section": "",
    "text": "Gender Classification CNN Demo\n\n\nA demo Shiny app that predicts the gender of an image using my custom trained convolutional neural network.\n\n\n\n\n\nNo matching items"
  }
]